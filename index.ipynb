{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ROOT preprocessing pipeline for machine learning with TensorFlow\n",
    "\n",
    "\n",
    "#### by Matthias Komm (CERN) <div align=right><img width=10% style=\"margin-right:10%\" src=\"figures/cms.png\"/></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prerequisites\n",
    "* setup of this notebook: python 2.7, tensorflow 1.6, keras 2.1.6, root 6.18\n",
    "* binaries taken from anaconda/conda-forge repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "* common machine learning frameworks: PyTorch, TensorFlow (+keras), MXNet, scikit-learn, XGBoost\n",
    "* frameworks require data for training to be typically in the form of numpy arrays, panda dataframes, etc.\n",
    "* convenient to store training data in npz or hdf5 files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example 1: MNIST\n",
    "training neural network on MNIST dataset for handwritten digit classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# note: matplotlib and ROOT needs to be imported before tensorflow/keras\n",
    "# this will otherwise cause a libpng version mismatch\n",
    "import matplotlib.pyplot as plt\n",
    "import ROOT\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils \n",
    "import numpy as np\n",
    "\n",
    "#download the MNIST dataset;\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(path='cache.npz')\n",
    "\n",
    "#at this point the dataset is being held in RAM\n",
    "print \"Training data set size: %.2f MB\" % ((X_train.size*X_train.itemsize)/1e6)\n",
    "print \"Test data set size: %.2f MB\" % ((X_test.size*X_test.itemsize)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#some preprocessing\n",
    "nb_classes = 10 # number of unique digits\n",
    "\n",
    "#convert number to one-hot encoding\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "\n",
    "#expand dimension; last dimension interpreted as color channel\n",
    "#here: 1 channel = grayscale\n",
    "X_train = np.expand_dims(X_train,axis=3)\n",
    "\n",
    "#train only the first 1000 images for this example\n",
    "X_train = X_train[:1000]\n",
    "Y_train = Y_train[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Setup convolutional neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "model_mnist = keras.models.Sequential()\n",
    "model_mnist.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "for _ in range(3):\n",
    "    model_mnist.add(keras.layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "    model_mnist.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model_mnist.add(keras.layers.Flatten())\n",
    "model_mnist.add(keras.layers.Dense(10,activation='relu'))\n",
    "model_mnist.add(keras.layers.Dense(10,name='last_dense'))\n",
    "model_mnist.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "model_mnist.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_mnist.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model_mnist.fit(X_train, Y_train, batch_size=128, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data for TensorFlow\n",
    "* TensorFlow (TF) backend for keras used here\n",
    "* calling `model_mnist.fit` populates tensor objects as follows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "#construct TF graph\n",
    "input_tensor = tf.placeholder(tf.float32,shape=(None,28,28,1))\n",
    "input_layer = keras.layers.Input(tensor=input_tensor)\n",
    "output = model_mnist(input_layer)\n",
    "\n",
    "#execute TF graph\n",
    "sess = K.get_session()\n",
    "sess.run(output, feed_dict={input_tensor: X_train[0:1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example 1: Summary\n",
    "* basic ingredients for constructing and training a neural network\n",
    "* data is being held in memory\n",
    "* format: numpy array\n",
    "* keras' `model.fit` method feeds data to TensorFlow using placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intermezzo: Machine learning for jet classification\n",
    "* collimated spray of particles (=jet) producted during hardonization of a quark or gluon\n",
    "* in CMS, particles are clustered according to <a href=\"https://arxiv.org/abs/0802.1189\">anti-kT algorithm</a> to construct jets\n",
    "* example multijet event recorded by the CMS experiment; jets are marked by the yellow cones\n",
    "<div style=\"width: 70%;\"><div style='border-width: 1px; border-style: solid; border-color: gray; padding: 10px;  background: white; color: gray; font-size: 0.65em'><img style=\"margin: auto;\" width=50% src=\"figures/event.jpg\"/>CMS Document 12150-v2</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* classification of jets according to their origin (b,c,uds quarks, gluons, boosted W, top quark)\n",
    "* several algorithms developed over the years; <a href=\"https://arxiv.org/abs/1712.07158\">JINST 13 (2018)</a>, <a href=\"https://arxiv.org/abs/2004.08262\">JINST 15 (2020)</a>\n",
    "* typical inputs: global jet features (e.g. kinematics), secondary vertices, clustered particles (charged tracks, neutrals from calorimeter deposits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example 2: Jet classification\n",
    "* using here a sample of simulated QCD events from the CMS <a href=\"http://opendata.cern.ch/record/12021\">open data set</a>\n",
    "* jet and constituent properties have been saved in a simple ROOT TTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import uproot\n",
    "import os\n",
    "import glob\n",
    "\n",
    "input_file_list = glob.glob('Samples/QCD_Pt-15to7000_unpacked_train1_[0-9]*.root')\n",
    "print \"Files:\",input_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#exploring the files\n",
    "uproot_file = uproot.open(\"Samples/QCD_Pt-15to7000_unpacked_train1_1.root\")\n",
    "jets = uproot_file['jets']\n",
    "print \"number of jets:\",len(jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#print some labels/features\n",
    "labels = ['isB','isC','isS','isUD','isG']\n",
    "features = ['global_pt','global_eta','nsv'] #note: global_pt is in log10(pt / 1 GeV)\n",
    "print \"%4s\"%(\"#jet\"),\n",
    "for label in labels:\n",
    "    print \"%6s\"%(label),\n",
    "for feature in features:\n",
    "    print \"%10s\"%(feature),\n",
    "print\n",
    "print \"-\"*100\n",
    "for i in range(10,20):\n",
    "    print \"%4i\"%(i),\n",
    "    for label in labels:\n",
    "        print \"%6i\"%(jets['jetorigin_'+label].array()[i]),\n",
    "    for feature in features:\n",
    "        print \"%10.2f\"%(jets[feature].array()[i]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#generator to iterate over input files\n",
    "def generate(file_list, labels, features, batch_size=10):\n",
    "    for file_name in file_list:\n",
    "        uproot_file = uproot.open('Samples/'+file_name)\n",
    "        jets = uproot_file['jets']\n",
    "        for batch_index in range(len(jets)/batch_size):\n",
    "            batch_features = []\n",
    "            batch_labels = []\n",
    "            for feature in features:\n",
    "                batch_features.append(jets[feature].array(\n",
    "                    entrystart=batch_index*batch_size,\n",
    "                    entrystop=(batch_index+1)*batch_size\n",
    "                ))\n",
    "            for label in labels:\n",
    "                batch_labels.append(jets['jetorigin_'+label].array(\n",
    "                    entrystart=batch_index*batch_size,\n",
    "                    entrystop=(batch_index+1)*batch_size\n",
    "                ))\n",
    "            yield np.stack(batch_features,axis=1), np.stack(batch_labels,axis=1)\n",
    "\n",
    "            \n",
    "for X,y in generate(os.listdir(\"Samples\"),labels,features):\n",
    "    print X\n",
    "    print y\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train a simple neural network to classify jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#build keras model\n",
    "model_jets = keras.models.Sequential()\n",
    "model_jets.add(keras.layers.Dense(10, activation='relu', input_shape=(len(features),)))\n",
    "for _ in range(3):\n",
    "    model_jets.add(keras.layers.Dense(10,activation='relu'))\n",
    "model_jets.add(keras.layers.Dense(len(labels)))\n",
    "model_jets.add(keras.layers.Activation('softmax'))\n",
    "model_jets.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_jets.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#train model using generator\n",
    "history = model_jets.fit_generator(generate(os.listdir(\"Samples\"),labels,features),steps_per_epoch=100, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example 2: Summary\n",
    "* data read sequentially from disk using `generator` pattern\n",
    "* advantages\n",
    "    * works with arbirary large data sets\n",
    "    * does not dictate decoder (here: uproot)\n",
    "    * allows to select features\n",
    "    * optional preprocessing possible\n",
    "* disadvantages\n",
    "    * I/O limited; training needs to wait until data has been read and processed\n",
    "    * no shuffeling of batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* obvious solution\n",
    "    * read data asychroniously from disk\n",
    "    * populate cache\n",
    "    * train on random batch from cache\n",
    "* technical problems\n",
    "    * need to deal with threads and points of synchronization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TensorFlow queue approach\n",
    "\n",
    "* TensorFlow v1 allows to build complex input pipelines using queues\n",
    "<div style=\"width: 80%;\"><div style='border-width: 1px; border-style: solid; border-color: gray; padding: 10px;  background: white;'><img style='margin: auto;' width=70% src=\"figures/AnimatedFileQueues.gif\"/></div></div>\n",
    "* first queue holds list of file names for reading\n",
    "* files are read in parallel\n",
    "* decoded data enqueued as tensors into second queue\n",
    "* second queue caches tensors from which (random) batches can be dequeued for training\n",
    "* problem: no native TensorFlow operation to read ROOT TTrees\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Working with queues\n",
    "* construct a FIFO or random queue\n",
    "* enqueue/dequeue elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    with tf.device('/cpu:0'):\n",
    "        queue_fifo = tf.FIFOQueue(\n",
    "            capacity=100, \n",
    "            dtypes=[tf.float32], \n",
    "            shapes=[()]\n",
    "        )\n",
    "        \n",
    "        queue_rnd = tf.RandomShuffleQueue(\n",
    "            capacity=100,\n",
    "            min_after_dequeue=1, \n",
    "            dtypes=[tf.float32], \n",
    "            shapes=[()],\n",
    "        )\n",
    "        \n",
    "        queue = queue_fifo\n",
    "        #queue = queue_rnd\n",
    "\n",
    "        element = tf.placeholder(tf.float32,shape=())\n",
    "        enqueue_op = queue.enqueue(element)\n",
    "        dequeue_op = queue.dequeue()\n",
    "        dequeue_many_op = queue.dequeue_many(4)\n",
    "        \n",
    "    init_op = tf.group(\n",
    "        tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer()\n",
    "    )\n",
    "\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    values = np.arange(0,10)\n",
    "    print 'values to be enqueued:',values    \n",
    "    for i in range(len(values)):\n",
    "        sess.run(enqueue_op, feed_dict = {element: values[i]})\n",
    "        \n",
    "    for i in range(3):\n",
    "        print 'dequeued:',sess.run(dequeue_op)\n",
    "    print 'dequeued many',sess.run(dequeue_many_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A TTree reader as TensorFlow operation\n",
    "* written in C++ as plugin for TensorFlow\n",
    "* linked against ROOT to read TTrees\n",
    "* employ <a href=\"https://cmake.org/\">cmake</a> for compiling the plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir Ops/build || rm -rf Ops/build/*\n",
    "cd Ops/build\n",
    "\n",
    "#create make file from cmake configuration\n",
    "cmake -DCMAKE_INSTALL_PREFIX=$PWD/release .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd Ops/build\n",
    "\n",
    "#compile and install library under given path\n",
    "make -j\n",
    "make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# add to python path for import\n",
    "sys.path.append(os.path.join(os.getcwd(),'Ops','build','release'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# module can now be imported\n",
    "import rtf\n",
    "print rtf.root_reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example 3: A simple pipeline\n",
    "* file name queue => root reader => tensor queue => random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def create_pipeline_simple(file_list,features_dict,batch_size=5):\n",
    "    # place all operations on cpu; leave gpu for training\n",
    "    # (note: this notebook has no gpu support)\n",
    "    with tf.device('/cpu:0'):\n",
    "        \n",
    "        # 1st queue hold random list of file names\n",
    "        file_list_queue = tf.train.string_input_producer(\n",
    "            file_list,\n",
    "            num_epochs=1,\n",
    "            seed = 234567,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        # custom reader will dequeue from queue and produce tensors\n",
    "        reader = rtf.root_reader(\n",
    "            file_list_queue, \n",
    "            features_dict, \n",
    "            \"jets\", # TTree name\n",
    "            batch=5 #numer of sequential reads\n",
    "        ).batch()\n",
    "\n",
    "        # tensors are enqueue in 2nd queue \n",
    "        batch = tf.train.shuffle_batch_join(\n",
    "            [reader],\n",
    "            batch_size=batch_size,\n",
    "            capacity=5*batch_size,\n",
    "            min_after_dequeue=2*batch_size,\n",
    "            seed = 234567,\n",
    "            enqueue_many=True\n",
    "        )\n",
    "        \n",
    "        # calling sess.run(batch) will dequeue a random batch\n",
    "        # of tensors from the queue\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "feature_dict_1 = {\n",
    "    \"globalvars\": {\n",
    "        \"branches\": ['global_pt','global_eta','nsv'],\n",
    "    },\n",
    "}\n",
    "\n",
    "feature_dict_2 = {\n",
    "    \"globalvars\": { # global jet features\n",
    "        \"branches\": ['global_pt','global_eta','nsv'],\n",
    "    },\n",
    "    \"truth\": { # jet label determined from simulation truth\n",
    "        \"branches\":[\n",
    "            'jetorigin_isB||jetorigin_isBB||jetorigin_isGBB||jetorigin_isLeptonic_B||jetorigin_isLeptonic_C',         \n",
    "            'jetorigin_isC||jetorigin_isCC||jetorigin_isGCC',\n",
    "            'jetorigin_isUD||jetorigin_isS',\n",
    "            'jetorigin_isG'       \n",
    "        ],\n",
    "    },\n",
    "    \"sv\" : { # secondary vertices inside jet\n",
    "        \"branches\":[\n",
    "            'sv_mass',\n",
    "            'sv_chi2',\n",
    "            'sv_dxy',        \n",
    "        ],\n",
    "        \"max\":2 # allow up to 2 vertices per jet; zero-padded\n",
    "    },\n",
    "}\n",
    "\n",
    "feature_dict = feature_dict_1\n",
    "\n",
    "file_list = glob.glob('Samples/QCD_Pt-15to7000_unpacked_train1_[0-9]*.root')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    batch = create_pipeline_simple(file_list,feature_dict)\n",
    "            \n",
    "    init_op = tf.group(\n",
    "        tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer()\n",
    "    )\n",
    "\n",
    "    sess.run(init_op)\n",
    "\n",
    "    # manages thread pool\n",
    "    coord = tf.train.Coordinator()\n",
    "    \n",
    "    # run queues asynchronous \n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # get a single batch\n",
    "    batch_value = sess.run(batch)\n",
    "    for k,v in batch_value.iteritems():\n",
    "        print k,v.shape\n",
    "        print v\n",
    "        print\n",
    "    \n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example 4: A realistic input pipeline\n",
    "* use multiple parallel readers to populate tensor queue\n",
    "* preprocess tensors with random sampling\n",
    "* goal: achieve same $p_\\mathrm{T}$ and $|\\eta|$ distribution per jet label to reduce bias => neural network is optimized at each ($p_\\mathrm{T}$, $|\\eta|$) point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# import realistic dict of features containing \n",
    "#  * jet labels from simulation ('truth')\n",
    "#  * global jet properties ('globalvar')\n",
    "#  * secondary vertex properties ('sv')\n",
    "#  * charged & neutral particle properties ('cpf' & 'npf')\n",
    "from realistic_feature_dict import feature_dict\n",
    "print \"%14s  |  %12s\"%(\"feature group\",\"number of features\")\n",
    "print \"-\"*40\n",
    "for k,v in feature_dict.iteritems():\n",
    "    if v.has_key('max'):\n",
    "        print \"%12s    |%8i x %-2i\"%(k,len(v['branches']),v['max'])\n",
    "    else:\n",
    "        print \"%12s    |%8i\"%(k,len(v['branches']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Create histograms for resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import my_root_style\n",
    "\n",
    "def create_weight_histograms(input_file_list,features):\n",
    "    hists_per_class = []\n",
    "    chain = ROOT.TChain('jets','jets')\n",
    "    for f in input_file_list:\n",
    "        chain.AddFile(f)\n",
    "        \n",
    "    for i,name in enumerate(features['truth']['names']):\n",
    "        hist = ROOT.TH2F(\n",
    "            name,\n",
    "            name+\";Jet log_{10}(p_{T} / 1 GeV);\",\n",
    "            10,1.3, 3.0, #log10(pt / 1 GeV) binning\n",
    "            3,-2.4,2.4 #eta binning\n",
    "        )\n",
    "        variable = features['truth']['branches'][i]\n",
    "        chain.Project(hist.GetName(),\"global_eta:global_pt\",variable)\n",
    "        hist.SetDirectory(0)\n",
    "        hists_per_class.append(hist)\n",
    "        \n",
    "    avg_events = np.mean(map(\n",
    "        lambda h: h.Integral()/h.GetNbinsX()/h.GetNbinsY(),\n",
    "        hists_per_class\n",
    "    ))\n",
    "    \n",
    "    output_file = ROOT.TFile(\"weights.root\",\"RECREATE\")\n",
    "    for hist in hists_per_class:\n",
    "        for etabin in range(hist.GetNbinsY()):\n",
    "            hist.SetBinContent(0,etabin+1,0)\n",
    "            hist.SetBinContent(hist.GetNbinsX()+1,etabin+1,0)\n",
    "            for ptbin in range(hist.GetNbinsX()):   \n",
    "               \n",
    "                xflavor = hist.GetBinContent(ptbin+1,etabin+1)\n",
    "                if xflavor<4.:\n",
    "                    hist.SetBinContent(ptbin+1,etabin+1,0.)\n",
    "                else:\n",
    "                    hist.SetBinContent(ptbin+1,etabin+1,avg_events/xflavor)\n",
    "                \n",
    "                hist.SetDirectory(output_file)\n",
    "    output_file.Write()\n",
    "    \n",
    "create_weight_histograms(\n",
    "    glob.glob('Samples/QCD_Pt-15to7000_unpacked_train1_[0-9]*.root'),\n",
    "    feature_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Inspecting the weights\n",
    "(note: weight > 1 means jets are oversampled which should be avoided in realistic applications since it can lead to overfitting of the neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "weightFile = ROOT.TFile(\"weights.root\")\n",
    "cv = ROOT.TCanvas(\"cv\",\"\",800,600)\n",
    "cv.Divide(2,2)\n",
    "for i,name in enumerate(feature_dict['truth']['names']):\n",
    "    cv.cd(i+1)\n",
    "    cv.SetLogy(1)\n",
    "    hist = weightFile.Get(name).ProjectionX()\n",
    "    hist.GetYaxis().SetTitle(\"Resample weight\")\n",
    "    hist.SetLineWidth(3)\n",
    "    hist.Draw(\"L\")\n",
    "cv.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Bulding the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def create_pipeline_realistic(file_list,features_dict,batch_size=5,nthreads=2):\n",
    "    # place all operations on cpu; leave gpu for training\n",
    "    # (note: this notebook has no gpu support)\n",
    "    with tf.device('/cpu:0'):\n",
    "        \n",
    "        # 1st queue hold random list of file names\n",
    "        file_list_queue = tf.train.string_input_producer(\n",
    "            file_list,\n",
    "            num_epochs=1,\n",
    "            seed = 234567,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        readers = []\n",
    "        resamplers = []\n",
    "        \n",
    "        for _ in range(nthreads):\n",
    "            # custom reader will dequeue from queue and produce tensors\n",
    "            reader = rtf.root_reader(\n",
    "                file_list_queue, \n",
    "                features_dict, \n",
    "                \"jets\", # TTree name\n",
    "                batch=5 #numer of sequential reads\n",
    "            ).batch()\n",
    "            \n",
    "            readers.append(reader)\n",
    "            \n",
    "            weight = rtf.classification_weights(\n",
    "                reader[\"truth\"],\n",
    "                reader[\"globalvars\"],\n",
    "                \"weights.root\",\n",
    "                features_dict['truth']['names'],\n",
    "                [0, 1]\n",
    "            )\n",
    "            resample = rtf.resampler(\n",
    "                weight,\n",
    "                reader\n",
    "            ).resample()\n",
    "\n",
    "            resamplers.append(resample)\n",
    "\n",
    "        # tensors are enqueue in 2nd queue \n",
    "        batch = tf.train.shuffle_batch_join(\n",
    "            #readers,\n",
    "            resamplers,\n",
    "            batch_size=batch_size,\n",
    "            capacity=5*batch_size,\n",
    "            min_after_dequeue=2*batch_size,\n",
    "            seed = 234567,\n",
    "            enqueue_many=True\n",
    "        )\n",
    "        \n",
    "        # calling sess.run(batch) will dequeue a random batch\n",
    "        # of tensors from the queue\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Training a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "file_list = glob.glob('Samples/QCD_Pt-15to7000_unpacked_train1_[0-9]*.root')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    K.set_session(sess)\n",
    "    batch = create_pipeline_realistic(\n",
    "        file_list,\n",
    "        feature_dict,\n",
    "        batch_size=20,\n",
    "        nthreads=2\n",
    "    )\n",
    "\n",
    "    from realistic_model import create_model\n",
    "    \n",
    "    \n",
    "    globalvars = keras.layers.Input(tensor=batch['globalvars'])\n",
    "    cpf = keras.layers.Input(tensor=batch['cpf'])\n",
    "    npf = keras.layers.Input(tensor=batch['npf'])\n",
    "    sv = keras.layers.Input(tensor=batch['sv'])\n",
    "    \n",
    "    nlabels = len(feature_dict['truth']['names'])\n",
    "\n",
    "    model = create_model(\n",
    "        globalvars,\n",
    "        cpf,\n",
    "        npf,\n",
    "        sv,\n",
    "        nlabels\n",
    "    )\n",
    "    #model.summary()\n",
    "    \n",
    "    predicted_labels = model.outputs[0]\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        labels=batch['truth'], \n",
    "        logits=predicted_labels,\n",
    "    ))\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "    \n",
    "    init_op = tf.group(\n",
    "        tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer()\n",
    "    )\n",
    "\n",
    "    sess.run(init_op)\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    pt = [[] for _ in range(nlabels)]    \n",
    "        \n",
    "    step = 0\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            step+=1\n",
    "            _,loss_value,batch_value = sess.run([opt,loss,batch])\n",
    "            \n",
    "            iclass = np.argmax(batch_value['truth'],axis=1)\n",
    "            \n",
    "            for ibatch in range(iclass.shape[0]):\n",
    "                pt[iclass[ibatch]].append(batch_value['globalvars'][ibatch,0])\n",
    "            if step%10==0:\n",
    "                print \"Step %i, loss=%.3f\\r\"%(step,loss_value),\n",
    "                \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print 'Done reading files for %i steps (loss=%.3f)' % (step,loss_value)\n",
    "    coord.request_stop()\n",
    "    coord.join()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    for ilabel in range(nlabels):\n",
    "        plt.hist(pt[ilabel], bins = 10, alpha=0.25, label=feature_dict['truth']['names'][ilabel])\n",
    "    plt.legend()\n",
    "    ax.set_xlabel(r'$\\mathrm{log10}(p_\\mathrm{T} /1\\,\\mathrm{GeV})$', fontsize=15)\n",
    "    ax.set_ylabel(r'#Jets', fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example 4: Summary\n",
    "* constructed input pipeline using two random queues\n",
    "* read data from multiple ROOT TTrees asynchronous\n",
    "* on-the-fly preprocessing: perform random sampling of tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outlook\n",
    "* presented ROOT TensorFlow pipeline as proof-of-concept\n",
    "* unfortunately TensorFlow queue system deprecated in TF2.X in favor of <a href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset\">Dataset API</a>; \n",
    "* main drawback: closed queues cannot be reopened; new tf.Session has to be constructed\n",
    "* currently working on adapting to Dataset API system\n",
    "* intermediate problem: linking TensorFlow and ROOT together (c++ ABI does not match for binaries taken from anaconda repositories)\n",
    "* no need to install all of ROOT anyway; a slim c++ ROOT I/O library to link against would be sufficient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Epilogue\n",
    "* basic ingredients to train a neural network\n",
    "* feeding data into TensorFlow\n",
    "* using `generator` pattern and uproot to feed data sequentially into keras/TensorFlow\n",
    "* introduction to TensorFlow queue system\n",
    "* custom operation to interface TensorFlow with ROOT \n",
    "* proof-of-concept for training neural networks directly on ROOT TTrees\n",
    "* no conversion to intermediate formats required\n",
    "* flexible system (select branches; perform preprocessing)\n",
    "* pipeline used in publication <a href=\"https://arxiv.org/abs/1912.12238\">arXiv:1912.12238</a>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:py27] *",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "rise": {
   "autolaunch": true,
   "font-size": "70%",
   "overlay": "<div style='position: fixed; left: 0px; top: 0px; width: 80%; height: 80%'><img src='figures/decay.jpg'/></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
